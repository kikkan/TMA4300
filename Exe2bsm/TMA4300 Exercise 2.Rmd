---
title: "Project 2"
author: "Erling Fause Steen og Christian Oppeg√•rd Moen"
date: "08 03 2022"
output: 
  bookdown::pdf_document2:
    toc_depth: '3'
    number_sections: false
  # pdf_document:
  # #   toc: no
  #   toc_depth: '3'
subtitle: Computer Intensive Statistical Methods
urlcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,
                      strip.white=TRUE,
                      prompt=FALSE,
                      cache=TRUE,
                      root.dir = "./Exe2bsm",
                      size="scriptsize",
                      fig.width=7, 
                      fig.height=5, 
                      fig.align = "center")
```


```{r imports}
library(ggplot2)
```

# Problem 1

We will look at a portion of the Tokyo rainfall dataset. The response is whether the amount of rainfall exceed 1 mm over a time period, and is given by

\begin{equation}(\#eq:1yt)
  y_t | \tau_t \sim \text{Bin}(n_t,\pi (\tau _t)), \ \ \pi(\tau_t)=\frac{\exp(\tau_t)}{1+\exp(\tau_t)}=\frac{1}{1+\exp(-\tau_t)}.
\end{equation}

## a)
We start by downloading the Tokyo rainfall dataset and plot the response as a function of t.

```{r loadData}
# Read the rain data. Might have to change wd. Should knit without.
# setwd(./Exe2bsm)
load("./rain.rda")
```

We start by plotting the amount of rainfall against each day. 
```{r displayData}
##Plotting the data
head(rain)
ggplot(data=rain, mapping=aes(x=day, y=n.rain))+geom_line()+xlab("Day")+ylab("Number of days with more than 1 mm rain")
```

From the plot, we can see that there are fewer days in the start of the year and in the end of the year with an amount of rainfall over 1 mm. This is in January and December. The number of days steadily increases until the beggining of the summer which seems to be the period with the most days with an amount of rainfall over 1 mm. Then, the amount of days decreases during july and august before increasing during the autumn. This is somewhat consistent with the results we get from googling the amount of days with precipitation in Tokyo, where we can see that June and September are the months with the most days with rainfall and December and January are the month with the most. 

## b) Likelihod
The likelihood of Equation \@ref(eq:1yt) is given by
$$
\begin{array}{rl}
  L(\pi (\tau_t)) &= \prod_{i=1}^{T} \left(
  \begin{array}{c}
    n_t \\ y_t
  \end{array} \right)
  \pi(\tau_t)^{y_t}(1-\pi(\tau_t)^{n_t-y_t} 
  \\
  &\propto \prod_{i=1}^{T} \pi(\tau_t)^{y_t}(1-\pi(\tau_t)^{n_t-y_t} 
  \\
  &= \prod_{t=1}^{T} \left(\frac{\exp(\tau_t)}{1+\exp(\tau_t)}\right)^{y_t}
  \left( 1- \frac{\exp(\tau_t)}{1+\exp(\tau_t)}\right)^{n_t - y_t},
\end{array}
$$
where $y_t = 1,2,...,39$ and $n_t = 39$ for $t \neq 60$, and $y_t = 1,2,...,10$ and $n_t = 10$ for $t \neq 60$.

## c) Posterior
$$
\begin{aligned}
  P(\sigma^2 | \tau, y) &= \frac{P(\sigma^2_u, \tau, y)}{P(\tau, y)} 
  \\
  &\propto  P(y | \sigma^2_u,\tau) P(\sigma^2_u,\tau)
  \\
  &= P(y | \sigma^2_u,\tau) P(\tau|\sigma^2_u)P(\sigma^2_u) \\
  &= \underbrace{\prod_{t=1}^{T} \left(\frac{\exp(\tau_t)}{1+\exp(\tau_t)}\right)^{y_t}
  \left( 1- \frac{\exp(\tau_t)}{1+\exp(\tau_t)}\right)^{n_t - y_t}}_{\text{Constant wrt }\sigma^2}\cdot \\
  &\quad \ \prod_{t=1}^{T} \frac{1}{\sigma_u} \exp\left\{ \frac{1}{2\sigma^2_u}(\tau_t - \tau_{t-1})^2 \right\} \cdot \frac{\beta^\alpha}{\Gamma(\alpha)} \left( \frac{1}{\sigma_u^2} \right)^{\alpha+1} exp\left\{ - \frac{\beta}{\sigma_u^2} \right\}
  \\
  &\propto \prod_{t=1}^{T} \frac{1}{\sigma_u} \exp\left\{ \frac{1}{2\sigma^2_u}(\tau_t - \tau_{t-1})^2 \right\} \cdot \frac{\beta^\alpha}{\Gamma(\alpha)} \left( \frac{1}{\sigma_u^2} \right)^{\alpha+1} exp\left\{ - \frac{\beta}{\sigma_u^2} \right\}
  \\
  &= \frac{1}{\sigma^{T-1}_u} exp\left\{ \frac{T-1}{2\sigma^2_u} \boldsymbol{\tau Q \tau} \right\} \cdot \frac{\beta^\alpha}{\Gamma(\alpha)} \left( \frac{1}{\sigma_u^2} \right)^{\alpha+1} exp\left\{ - \frac{\beta}{\sigma_u^2} \right\}
\end{aligned}
$$
which should be the core of an inverse gamma.

## d) Acceptance probability
Let $\mathcal{I} \subseteq \{1,2,...,366\}$ be a set of time indices, and let $- \mathcal{I} = \{1,2,...,366\} \setminus \mathcal{I}$. Furthermore, let $\boldsymbol{\tau}'$ denote the proposed values for $\boldsymbol{\tau}$. Then, by using iterative conditioning, the acceptance probability is given by
$$
 \alpha(\boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y}) 
 = \text{min} \left( 1, \frac{P( \boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})}
 {P( \boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})} 
 \frac{Q( \boldsymbol{\tau}_\mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})}
 {Q(\boldsymbol{\tau}'_ \mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})}
 \right),
$$
where our prior proposal distribution is $Q(\boldsymbol{\tau}'_\mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2, \boldsymbol{y}) = P(\boldsymbol{\tau}'_\mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2)$. By considering
$$
\begin{aligned}
  P( \boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y}) &= \frac{P( \boldsymbol{\tau}'_ \mathcal{I}, \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})}{P( \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y})} 
  \\
  &= \frac{P(\boldsymbol{y}| \boldsymbol{\tau}'_ \mathcal{I}, \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)P(\boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)P(\boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2) P(\boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}
  \\
  &= \frac{\overbrace{P(\boldsymbol{y}| \boldsymbol{\tau}'_ \mathcal{I}, \boldsymbol{\tau}_ {-\mathcal{I}})}^{\text{Conditionally independent}} P(\boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}
  \\
  &= \frac{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}'_ \mathcal{I})P(\boldsymbol{y}_\mathcal{-I}| \boldsymbol{\tau}_ \mathcal{-I}) P(\boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}
\end{aligned}
$$
and equally
$$
  P( \boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y}) 
  = 
  \frac{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}_ \mathcal{I})P(\boldsymbol{y}_\mathcal{-I}| \boldsymbol{\tau}_ \mathcal{-I}) P(\boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}
$$
the acceptance probability becomes
$$
\begin{aligned}
  \alpha(\boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2, \boldsymbol{y}) &= \text{min} \left( 1, \frac{{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}'_ \mathcal{I})P(\boldsymbol{y}_\mathcal{-I}| \boldsymbol{\tau}_ \mathcal{-I}) P(\boldsymbol{\tau}'_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}/{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}}
  {{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}_ \mathcal{I})P(\boldsymbol{y}_\mathcal{-I}| \boldsymbol{\tau}_ \mathcal{-I}) P(\boldsymbol{\tau}_ \mathcal{I}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}/{P(\boldsymbol{y}| \boldsymbol{\tau}_ {-\mathcal{I}}, \sigma_u^2)}}
  \frac{P(\boldsymbol{\tau}_\mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2)}{P(\boldsymbol{\tau}'_\mathcal{I}|\boldsymbol{\tau}_{-\mathcal{I}}, \sigma_u^2)} 
  \right)
  \\
  &= \text{min} \left( 1, \frac{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}'_ \mathcal{I})}{P(\boldsymbol{y}_\mathcal{I}| \boldsymbol{\tau}_ \mathcal{I})} 
  \right)
\end{aligned}
$$


