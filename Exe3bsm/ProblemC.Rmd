---
title: "Title"
author: "Christian Oppeg√•rd Moen"
date: "DD MM YYYY"
output: 
  bookdown::pdf_document2:
    toc_depth: '3'
    number_sections: false
  # pdf_document:
  # #   toc: no
  #   toc_depth: '3'
subtitle: Course
urlcolor: blue
editor_options: 
  chunk_output_type: console
header-includes:
- \usepackage[width=0.8\textwidth]{caption}
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(
  echo = T, tidy=T, message=F, warning=F,
  strip.white=F,
  prompt=F,
  cache=T,
  root.dir = "./Exe3bsm",
  size="scriptsize",
  fig.width=7, 
  fig.height=5, 
  fig.align = "center"
)
```

```{r load, options}
source("./additionalFiles/probAhelp.R")
source("./additionalFiles/probAdata.R")
figPath = "./Figures/"
```

# Problem C: The EM-algorithm and bootstrapping

Let $x_1,...x_n$ and $y_1,...,y_n$ be independet random variables, where
$$
x_i \sim \text{Exp}(\lambda_0) \ \ \text{and} \ \ y_i \sim \text{Exp}(\lambda_1)
$$

We observe

$$
z_i =\text{max}(x_i, y_i) \ \ \text{for} \ \ i=1,...,n
$$

and

$$
u_i=I(x_i \geq y_i) \ \ \text{for} \ \ i=1,...,n.
$$

## 1.

The joint distribution of $(x_i, y_i),i=1,..n$ is given by

$$
f(x, y | \lambda_0, \lambda_1)=\prod_{i=1}^{n} f_{x}(x_i | \lambda_0) \cdot f_{y}(y_i|\lambda_1)
$$
$$
=\prod_{i=1}^{n}\lambda_0 e^{-\lambda_0 x_i} \cdot \lambda_1 e^{-\lambda_1 y_i}.
$$
This means that the log likelihood is given by
$$
\ln f(x,y|\lambda_0, \lambda_1)=\sum_{i=1}^{n} \ln \lambda_0+ \ln \lambda_1-\lambda_0 x_i - \lambda_1 y_i=n(\ln \lambda_0+ \ln \lambda_1)-\lambda_0\sum_{i=1}^n x_i -\lambda_1\sum_{i=1}^n y_i \quad.
$$
We want to find
$$
E\left[ \ln f(x,y|\lambda_0, \lambda_1)| z, u, \lambda_0^{(t)}, \lambda_1^{(t)} \right].
$$

which is given by

$$
Q(\lambda_0, \lambda_1 | \lambda_0^{(t)}, \lambda_1^{(t)})=E \left[\sum_{i=1}^{n}n(\ln \lambda_0+ \ln \lambda_1)-\lambda_0\sum_{i=1}^n x_i -\lambda_1\sum_{i=1}^n y_i \ \ | \ \ z,u,\lambda_0^{(t)}, \lambda_1^{(t)} \right]
$$
$$
=-n(\ln\lambda_0+\ln\lambda_1) -\lambda_0\sum_{i=1}^n E(x_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)}) -\lambda_1\sum_{i=1}^n E(y_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)}).
$$
Now, we want to find $E(x_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)})$ and $E(y_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)}).$ We start by considering the first conditional expectation. This can found by first considering
$$
\begin{aligned}
  f(x_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)})  
  &= \begin{cases} z_i \quad \quad \quad \quad \quad \text{for} & u_i=1 \\ \frac{\lambda_0^{(t)}\exp(-\lambda_0^{(t)}x_i)}{1-\exp(-\lambda_0^{(t)}z_i)} \ \ \text{for} & u_i=0 \end{cases} \quad.
\end{aligned}
$$
The expectation is given by

$$
E[x_i|z_i, u_i, \lambda_0^{(t)}, \lambda_1^{(t)}]=u_i z_i + (1-u_i)\int_{0}^{z_i} x_i \frac{\lambda_0^{(t)}\exp(-\lambda_0^{(t)}x_i)}{1-\exp(-\lambda_0^{(t)}z_i)} dx_i
$$
where

$$
\int_{0}^{z_i} x_i \frac{\lambda_0^{(t)}\exp(-\lambda_0^{(t)}x_i)}{1-\exp(-\lambda_0^{(t)}z_i)} dx_i=
\left [- \frac{(\lambda_0^{(t)}x+1)\exp(-\lambda_0^{(t)} \cdot (x_i-z_i))}{\lambda_0^{(t)}(1-\exp(\lambda_0 z))} \right]_{0}^{z_i}
$$
$$
=\frac{\exp(\lambda_0^{(t)} z_i)- \lambda_0 z_i-1}{\lambda_0^{(t)} \cdot (\exp(\lambda_0^{(t)}-1))} \implies
$$
$$
E[x_i|z_i, u_i, \lambda_0^{(t)}, \lambda_1^{(t)}]=u_i z_i+(1-u_i) \cdot \frac{\exp(\lambda_0^{(t)} z_i)- \lambda_0 z_i-1}{\lambda_0^{(t)} \cdot (\exp(\lambda_0^{(t)}-1))}.
$$
We also need to find $E[y_i|z_i, u_i, \lambda_0^{(t)}, \lambda_1^{(t)}]$. We first consider the pdf

$$
\begin{aligned}
  f(y_i\mid z_i,u_i,\lambda_0^{(t)},\lambda_1^{(t)})  
  &= \begin{cases} z_i \quad \quad \quad \quad \quad \text{for} & u_i=1 \\ \frac{\lambda_1^{(t)}\exp(-\lambda_1^{(t)}y_i)}{1-\exp(-\lambda_1^{(t)}z_i)} \ \ \text{for} & u_i=0 \end{cases} \quad.
\end{aligned}
$$
The conditional expectation is given by

$$
E[y_i|z_i, u_i, \lambda_0^{(t)}, \lambda_1^{(t)}]=(1 - u_i) z_i + u_i \int_{0}^{z_i} y_i \frac{\lambda_1^{(t)} \exp\left\{-\lambda_1^{(t)} y_i\right\}}{1 - \exp\left\{-\lambda_1^{(t)} z_i\right\}} dy_i 
$$
where

$$
\int_{0}^{z_i} y_i \frac{\lambda_1^{(t)}\exp(-\lambda_1^{(t)}y_i)}{1-\exp(-\lambda_1^{(t)}z_i)} dy_i=

\frac{\exp({\lambda_1^{(t)} z_i})-\lambda_1^{(t)}-1}{\lambda_1^{(t)}(\exp(\lambda_1^{(t) }z_i)-1)}
$$
## 2.



In this problem we want to implement the EM-algorithm. We have found the conditional expectation $Q(\lambda_0,\lambda_1)=Q(\lambda_0, \lambda_1 | \lambda_0^{(t)}, \lambda_1^{(t)}).$ This corresponds to the E-step in the EM algorithm. In the M-step of the algorithm is to determine 

$$
(\lambda_0^{(t+1)}, \lambda_1^{(t+1)})=\text{argmax} \ \ Q(\lambda_0, \lambda_1).
$$

This can be found be finding the partial derivates and $Q(\lambda_0, \lambda_1)$ and set them equal to zero. 

$$
\frac{\partial}{\partial \lambda_0} Q(\lambda_0, \lambda_1)=
\frac{n}{\lambda_0}-\sum_{i=1}^{n} \left ( u_i z_i+(1-u_i) \left ( \frac{1}{\lambda_0^{(t)}}-\frac{z_i}{e^{\lambda_0^{(t)}z_i}-1} \right ) \right)=0
$$

$$
\frac{\partial}{\partial \lambda_1} Q(\lambda_0, \lambda_1)=
\frac{n}{\lambda_1}-\sum_{i=1}^{n} \left ( u_i z_i+(1-u_i) \left ( \frac{1}{\lambda_1^{(t)}}-\frac{z_i}{e^{\lambda_1^{(t)}z_i}-1} \right ) \right)=0
$$

We solve these two equations for $\lambda_0$ and $\lambda_1$ respectively. This gives the M-step

$$
\lambda_0^{(t+1)}=n/\sum_{i=1}^{n} \left ( u_i z_i+(1-u_i) \left ( \frac{1}{\lambda_0^{(t)}}-\frac{z_i}{e^{\lambda_0^{(t)}z_i}-1} \right ) \right)
$$
$$
\lambda_1^{(t+1)}=n/\sum_{i=1}^{n} \left ( u_i z_i+(1-u_i) \left ( \frac{1}{\lambda_1^{(t)}}-\frac{z_i}{e^{\lambda_1^{(t)}z_i}-1} \right ) \right)
$$
Let $\lambda^{(t)}=(\lambda_0^{(t)}, \lambda_1^{(t)}).$
We want to implement the EM-algorithm and we use the convergence criterion

$$
d(x^{(t+1)}, x^{t})= || {\lambda}^{(t+1)} - {\lambda}^{(t)}||_2<\epsilon.
$$

```{r dataC, include=FALSE}
u<-read.csv("./additionalFiles/u.txt")
z<-read.csv("./additionalFiles/z.txt")
```

The function below returns the conditional expectation, that is the E-step of the EM algorithm.

```{r}
cond_expectation <- function(lambda0, lambda1,lambda0t,lambda1t, u, z)
{
  n=length(u)
  exp=n*(log(lambda0)+log(lambda1))-(lambda0*sum(u*z+(1-u)*(1/lambda0t-(z)/(exp(lambda0t*z)-1))))-(lambda1*sum(u*z+(1-u)*(1/lambda1t-(z)/(exp(lambda1t*z)-1))))
return(exp)
}
```

Under is a function that implement M-step.
```{r}
M_step<- function(lambda0t,lambda1t,u,z)
{
  lambda0next=n/(sum(u*z+(1-u)*(1/lambda0t-(z)/(exp(lambda0t*z)-1))))
  lambda1next=n/(sum(u*z+(1-u)*(1/lambda1t-(z)/(exp(lambda1t*z)-1))))
  
  return(list(lambda0=lambda0next, lambda1=lambda1next))
}
```

Under the ME algorithm is implemented

```{r}
ME_algorithm<- function(lambda,u,z, epsilon=10e-5)
{
  i=0
  lambda0=lambda[0]
  lambda1=lambda[1]
  while(norm<epsilon && i<500 )
  {
    #E-step
    Q=cond_expectation(lambda0, lambda1, )
    #M-step
    
  }
}
```


```{r}
l<-numeric(2)
l
```
## 4.

We want to find an analytical formula for $f_{Z_i,U_i}(z_i, u_i| \lambda_0, \lambda_1).$

$$
f_{Z_i,U_i}(z_i, u_i | \lambda_0, \lambda_1)=P(\text{max}(X_i, Y_i)=z , I(X_i \geq Y_i)=u_i | \lambda_0, \lambda_1)
$$
$$
=u_i P(\text{max}(X_i, Y_i)=z_i, X)
$$


